{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyOVy6XlVl8q7WGSneScKKu6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cyzUGS5oNRdz"},"source":["#BERT masked LM filling"]},{"cell_type":"code","metadata":{"id":"vzzjif3AqBb0"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xEUWMc-4LM_"},"source":["import tensorflow as tf\n","\n","from IPython.display import clear_output\n","from transformers import BertTokenizer, TFBertForMaskedLM"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ha3N8sy84UqL"},"source":["PRETRAINED_MODEL_NAME = \"bert-base-chinese\"  # 指定繁簡中文 BERT-BASE 預訓練模型\n","\n","# 取得此預訓練模型所使用的 tokenizer\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n","model = TFBertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME, return_dict=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeoGCj297Yyl"},"source":["text = \"等到潮水退了，就知道誰沒穿褲子。\"\n","masked_index = 5 \n","text = text.replace(text[masked_index - 1], \" [MASK] \")\n","inputs = tokenizer(text, return_tensors=\"tf\")\n","tokens = tokenizer.convert_ids_to_tokens(inputs.input_ids[0])\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","print(text)\n","print(tokens)\n","print(ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBesJ9Xb-2rq"},"source":["outputs = model(inputs)\n","predictions = outputs.logits\n","\n","# 將 [MASK] 位置的機率分佈取 top k 最有可能的 tokens 出來\n","k = 3\n","masked_pred = predictions[0, masked_index]\n","masked_softmax = tf.nn.softmax(predictions[0, masked_index], -1)\n","probs, indices = tf.math.top_k(masked_softmax, k)\n","\n","predicted_tokens = tokenizer.convert_ids_to_tokens(indices)\n","\n","# 顯示 top k 可能的字。一般我們就是取 top 1 當作預測值\n","print(\"輸入 tokens ：\", tokens[:10], '...')\n","print('-' * 50)\n","for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n","    tokens[masked_index] = t\n","    print(\"Top {} ({:2}%)：{}\".format(i, int(p * 100), tokens[:10]), '...')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o2KYbkAyNc1p"},"source":["# BERT visualization"]},{"cell_type":"code","metadata":{"id":"DwYK4Pi0EbkR"},"source":["# 安裝 BertViz\n","import sys\n","!test -d bertviz_repo || git clone https://github.com/jessevig/bertviz bertviz_repo\n","if not 'bertviz_repo' in sys.path:\n","  sys.path += ['bertviz_repo']\n","\n","# import packages\n","from transformers import BertTokenizer, BertModel\n","from bertviz import head_view\n","\n","# 在 jupyter notebook 裡頭顯示 visualzation 的 helper\n","def call_html():\n","  import IPython\n","  display(IPython.core.display.HTML('''\n","        <script src=\"/static/components/requirejs/require.js\"></script>\n","        <script>\n","          requirejs.config({\n","            paths: {\n","              base: '/static/base',\n","              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.8/d3.min\",\n","              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n","            },\n","          });\n","        </script>\n","        '''))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJJT3j4QKkMq"},"source":["# 記得我們是使用中文 BERT\n","model_version = 'bert-base-chinese'\n","model = BertModel.from_pretrained(model_version, output_attentions=True)\n","tokenizer = BertTokenizer.from_pretrained(model_version)\n","\n","# 情境 1 的句子\n","sentence_a = \"胖虎叫大雄去買漫畫，\"\n","sentence_b = \"回來慢了就打他。\"\n","\n","# 得到 tokens 後丟入 BERT 取得 attention\n","inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n","token_type_ids = inputs['token_type_ids']\n","input_ids = inputs['input_ids']\n","attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n","input_id_list = input_ids[0].tolist() # Batch index 0\n","tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n","call_html()\n","\n","# 交給 BertViz 視覺化\n","head_view(attention, tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-jtHODxAKkQy"},"source":["# 情境 2 的句子\n","sentence_a = \"妹妹說胖虎是「胖子」\"\n","sentence_b = \"他聽了很不開心。\"\n","\n","# 得到 tokens 後丟入 BERT 取得 attention\n","inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n","token_type_ids = inputs['token_type_ids']\n","input_ids = inputs['input_ids']\n","attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n","input_id_list = input_ids[0].tolist() # Batch index 0\n","tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n","call_html()\n","\n","# 交給 BertViz 視覺化\n","head_view(attention, tokens)"],"execution_count":null,"outputs":[]}]}